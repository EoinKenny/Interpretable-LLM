{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e13cf80-8be6-485a-af87-00566c8f5f5d",
   "metadata": {},
   "source": [
    "# Gemma 2 and Sparse-Autoencoders\n",
    "## Todo:\n",
    "* ~~Write hook function for grabbing all residule connections in LLM~~\n",
    "* Develop method\n",
    "* Write zero shot baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f041e52-d4ce-402b-a8b2-ef24ecbba4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from sae_lens import SAE  # pip install sae-lens\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from huggingface_hub import hf_hub_download, notebook_login\n",
    "\n",
    "from funcs import make_prompt, pre_process_df, extract_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2bbd7f-3340-4d9b-8984-90127bec446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f76169-de4b-4e9b-bbcc-cca0ab4d1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c01c1bd-e1f6-4abb-8c17-80c1a573bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:3'\n",
    "dataset = 'imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66b1463-a07f-4fe1-9445-ebe0dea16d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf71d35a742413f8129efbf36a7990c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False) # avoid blowing up mem\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    device_map=device,\n",
    "    token='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',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a6c5e7-fd6e-4776-bd16-c623cfe7041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\",\n",
    "                                          token='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',\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9171b436-233d-4516-a306-67bac0b835e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The input text\n",
    "# prompt = \"Would you be able to travel through time using a wormhole?\"\n",
    "\n",
    "# # Use the tokenizer to convert it to tokens. Note that this implicitly adds a special \"Beginning of Sequence\" or <bos> token to the start\n",
    "# inputs = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "# print(inputs)\n",
    "\n",
    "# # Pass it in to the model and generate text\n",
    "# outputs = model.generate(input_ids=inputs, max_new_tokens=50)\n",
    "# print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e69b65-6f90-400d-9e12-00f934a009fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/'+dataset+'.csv')\n",
    "df = pre_process_df(df, dataset)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2fa73-e1ef-418b-bd63-a4fa66c2cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this for different datasets\n",
    "text     = row.text\n",
    "label    = row.label\n",
    "\n",
    "messages = make_prompt(text, dataset)\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "# Create attention mask\n",
    "attention_mask = encodeds.ne(tokenizer.pad_token_id).long() if tokenizer.pad_token_id is not None else torch.ones_like(encodeds).long()\n",
    "\n",
    "encodeds = encodeds.to(model.device)\n",
    "attention_mask = attention_mask.to(model.device)\n",
    "\n",
    "generated_ids = model.generate(encodeds, attention_mask=attention_mask, max_new_tokens=2000, do_sample=False)\n",
    "response = tokenizer.batch_decode(generated_ids)[0]\n",
    "prediction = extract_answer(response.split('end_header_id')[-1])\n",
    "    \n",
    "print(response.split('[/INST]')[-1])\n",
    "print('\\n\\n\\n =====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c505b-bf9e-443b-a0d6-de277309ca03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26e52e-d041-4753-aca5-678566eca931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702241a1-3581-42de-b7a5-9be39f2bf5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cff8a9-b573-475d-b62f-5d52cd8b7911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d62bac4-ad6b-4fb8-a43d-d61dc638e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_residual_stream_activations(model, inputs):\n",
    "    activations = []\n",
    "    \n",
    "    def gather_act_hook(layer_index):\n",
    "        def hook(mod, inputs, outputs):\n",
    "            activations.append(outputs[0].detach())\n",
    "        return hook\n",
    "    \n",
    "    handles = []\n",
    "    for i in range(len(model.model.layers)):\n",
    "        handle = model.model.layers[i].register_forward_hook(gather_act_hook(i))\n",
    "        handles.append(handle)\n",
    "    \n",
    "    _ = model(inputs)\n",
    "    \n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b514c9d4-4ad7-4df9-97d4-f937531e2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_act = gather_residual_stream_activations(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a76445-7d39-469f-8351-0babe7ec9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gemma-scope-2b-pt-res-canonical\",\n",
    "    sae_id = \"layer_20/width_16k/canonical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb9ff0-5f38-4fa8-b8e3-a4d191ec8802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19117464-07f1-4d9c-befd-30036e510560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAE(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_input): HookPoint()\n",
       "  (hook_sae_acts_pre): HookPoint()\n",
       "  (hook_sae_acts_post): HookPoint()\n",
       "  (hook_sae_output): HookPoint()\n",
       "  (hook_sae_recons): HookPoint()\n",
       "  (hook_sae_error): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35715e11-58ed-489e-bd58-695bca44f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_acts = sae.encode(target_act.to(torch.float32))\n",
    "recon = sae.decode(sae_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbc2d5a-0f7b-42d0-a230-768ffc6c01c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8887, device='cuda:1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.mean((recon[:, 1:] - target_act[:, 1:].to(torch.float32)) **2) / (target_act[:, 1:].to(torch.float32).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326e5b35-44d7-4043-ba79-4704a82c951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7017,   47,   65,   70,   55,   72,   65,   75,   80,   72,   68,   93,\n",
       "           86,   89]], device='cuda:1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sae_acts > 1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe5cea-7ea7-4a4d-a733-8dafb0bd8069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a683a-7e80-4abc-aca7-05fd3b0a0e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b7505-4cfc-4a3b-8757-a2371efc9f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd10c63-64d7-4c66-86d1-57d2977de9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c97556-e098-4cc4-8e91-57365c972bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae88b77-0dc5-4420-bc27-95e993842443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6518257-1711-4892-b7b6-03cbcba5b161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
